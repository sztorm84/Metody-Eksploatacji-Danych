{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METODY EKSPLORACJI DANYCH\n",
    "## Laboratorium. Klasyfikacja na podstawie klasyfikatora bayesowskiego i najbliższego sąsiedztwa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie bibliotek i danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Post     class\n",
      "0  [blog] Using Nullmailer and Mandrill for your ...  Mandrill\n",
      "1  [blog] Using Postfix and free Mandrill email s...  Mandrill\n",
      "2  @aalbertson There are several reasons emails g...  Mandrill\n",
      "3  @adrienneleigh I just switched it over to Mand...  Mandrill\n",
      "4  @ankeshk +1 to @mailchimp We use MailChimp for...  Mandrill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Domin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\Domin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C://Users//Domin//Desktop//semestr5//MED//Lab1//LAB3//MED-lab-3-Zad 3-Mandrill-Dane.xlsx\"\n",
    "df_mandrill = pd.read_excel(file_path, sheet_name=\"dot. aplikacji Mandrill\")\n",
    "df_other = pd.read_excel(file_path, sheet_name=\"dot. innych\")\n",
    "\n",
    "df_mandrill['class'] = 'Mandrill'\n",
    "df_other['class'] = 'inne'\n",
    "\n",
    "df = pd.concat([df_mandrill, df_other], ignore_index=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Domin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Domin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Domin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pobranie zasobów NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'test', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "print(word_tokenize(\"This is a test sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    blog using nullmailer mandrill ubuntu linux se...\n",
      "1    blog using postfix free mandrill email service...\n",
      "2    aalbertson several reason email go spam mind s...\n",
      "3    adrienneleigh switched mandrill let see improv...\n",
      "4    ankeshk mailchimp use mailchimp marketing emai...\n",
      "Name: processed_post, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lista słów przystankowych dla języka angielskiego\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Funkcja do przetwarzania tekstu\n",
    "def preprocess_text(text):\n",
    "    # Tokenizacja\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Usunięcie stop words i lematyzacja\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Przetwarzanie tekstów w kolumnie 'Post'\n",
    "df['processed_post'] = df['Post'].apply(preprocess_text)\n",
    "\n",
    "print(df['processed_post'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie reprezentacji TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Ograniczenie liczby cech\n",
    "x = vectorizer.fit_transform(df['processed_post'])\n",
    "\n",
    "# Ekstrakcja etykiet\n",
    "y = df['class']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Mandrill       0.93      1.00      0.96        27\n",
      "        inne       1.00      0.94      0.97        33\n",
      "\n",
      "    accuracy                           0.97        60\n",
      "   macro avg       0.97      0.97      0.97        60\n",
      "weighted avg       0.97      0.97      0.97        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie i trenowanie modelu\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predykcje na zbiorze testowym\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Ocena modelu\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
